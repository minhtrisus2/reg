import streamlit as st
from PIL import Image
import torch
import timm
import json
from urllib.request import urlopen

# --- PH·∫¶N 1: T·∫¢I M√î H√åNH V√Ä NH√ÉN (·ªîN ƒê·ªäNH) ---

@st.cache_resource
def load_model():
    """T·∫£i m√¥ h√¨nh AI b·∫±ng PyTorch v√† Timm.
    H√†m n√†y ch·ªâ ch·∫°y m·ªôt l·∫ßn duy nh·∫•t."""
    model = timm.create_model('mobilenetv3_large_100', pretrained=True)
    model.eval()
    return model

@st.cache_data
def load_labels():
    """T·∫£i danh s√°ch nh√£n t·ª´ file JSON.
    H√†m n√†y ƒë√£ ƒë∆∞·ª£c s·ª≠a l·ªói tri·ªát ƒë·ªÉ."""
    labels_url = "https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json"
    return json.load(urlopen(labels_url))

# Kh·ªüi t·∫°o m√¥ h√¨nh v√† nh√£n
model = load_model()
labels = load_labels()

# --- PH·∫¶N 2: H√ÄM LOGIC NH·∫¨N D·∫†NG ---

def recognize_image(image):
    """X·ª≠ l√Ω v√† nh·∫≠n d·∫°ng ·∫£nh."""
    try:
        # Chu·∫©n b·ªã ·∫£nh ƒë·ªÉ ƒë∆∞a v√†o m√¥ h√¨nh
        data_config = timm.data.resolve_data_config(model)
        transforms = timm.data.create_transform(**data_config, is_training=False)
        tensor = transforms(image).unsqueeze(0)
        
        # Ch·∫°y d·ª± ƒëo√°n
        with torch.no_grad():
            out = model(tensor)
            
        # X·ª≠ l√Ω k·∫øt qu·∫£ tr·∫£ v·ªÅ
        probabilities = torch.nn.functional.softmax(out[0], dim=0)
        top_prob, top_catid = torch.topk(probabilities, 1)
        
        confidence = top_prob.item() * 100
        label_name = labels[top_catid.item()].replace('_', ' ')
        
        # Tr·∫£ v·ªÅ chu·ªói k·∫øt qu·∫£ chuy√™n nghi·ªáp
        return f"ƒê·ªëi t∆∞·ª£ng ƒë∆∞·ª£c x√°c ƒë·ªãnh l√† **{label_name.capitalize()}** v·ªõi ƒë·ªô tin c·∫≠y **{confidence:.2f}%**."
    except Exception as e:
        return f"ƒê√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω ·∫£nh: {e}"

# --- PH·∫¶N 3: X√ÇY D·ª∞NG GIAO DI·ªÜN WEB ---

st.set_page_config(layout="wide", page_title="Bot Nh·∫≠n D·∫°ng ·∫¢nh")
st.title("ü§ñ Bot Nh·∫≠n D·∫°ng H√¨nh ·∫¢nh")
st.write("T·∫£i l√™n m·ªôt b·ª©c ·∫£nh, v√† AI s·∫Ω cho b·∫°n bi·∫øt n√≥ nh√¨n th·∫•y g√¨.")

uploaded_file = st.file_uploader("Ch·ªçn m·ªôt t·ªáp ·∫£nh...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    image = Image.open(uploaded_file).convert("RGB")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.image(image, caption="·∫¢nh b·∫°n ƒë√£ t·∫£i l√™n", use_container_width=True)
    
    with col2:
        with st.spinner("Bot ƒëang ph√¢n t√≠ch..."):
            result = recognize_image(image)
            st.success("Ph√¢n t√≠ch ho√†n t·∫•t!")
            st.markdown("### K·∫øt qu·∫£:")
            st.markdown(result)
